\section{Method}
Working with financial market data requires reliable data providers with high-quality data available. While many provider options are available, the primary considerations were Yahoo Finance, EODHD and Massive (formerly Polygon.io) for stock data, along with Coinbase and Binance for crypto currency data. For crypto currency data, the most consistent dataset, at least for Bitcoin (BTC), was sourced from Coinbase. Regarding stock data, the selected provider was Massive, as they provide access to consistent historical data across the American stock market. Due to both providers being free to use, along with their consistent data quality, made them the selected providers for the crypto currency market and stock market, respectively\todo{source for providers}.

Since financial time series data is often represented through the Open-High-Low-Close (OHLC) format, and the aim of the project is to make a general purpose time series prediction framework, this format must be generalized. To represent financial market data as general purpose time series, each OHLC entry is split in multiple series, where each serie only has a single vector of data points representing each metric. Each serie represents the metadata concerning a set of data points, such as asset, metric, data set time span, and resolution of the time intervals. Each data point is represented as a value, a time interval and a corresponding serie identifier. This relation allows for a uniform way to represent time series, regardless of domain. All data points are single values at specific time frame, and the interpretation of the value depends on the metadata of the related serie.

To store time series efficiently, the storage system would advantageously support high-volume data ingestion, as well as fast queries on large tables. This helps allow efficient addition of new time series with historical data, and update existing time series continuously. It also allows for responsive querying on data points during strategy backtesting. Furthermore, due to the relation between the series and data points, a relational database is preferable.

For this task, ClickHouse was selected as the database management system. The relational column-oriented architecture of the storage system allows for fast indexing on tables with many entries, which in this case increases the efficiency of the data point extraction process \todo{source}. This efficient querying along with data types like high-precision floating point numbers and time formats, made ClickHouse a suitable choice as database management system for general purpose time series. 