\section{Contribution}

%Strategy Structure
\subsection{Strategy Structure}

The design of the strategy components was based on widely adopted statistical models and data-manipulation techniques. These building blocks were integrated into a modular framework in which strategies are represented as DAGs. Each node performs a well-defined transformation, such as fetching data, computing indicators, evaluating conditions or generating signals. Nodes are connected via typed inputs and outputs to produce end-to-end trading logic.

\todo{AssetNodes retriever kun en "metric", det er en seperate global setting der skaffer fuld OHLCV data til at fuldføre en korrekt finansiel backtest}\textbf{Assets.}
Asset nodes retrieve historical price data from the Data Warehouse API for a specified trading pair and timeframe. Depending on the simulation mode, they either supply full OHLCV candlesticks (for realistic trade-level execution) or a single selected price metric (Open, High, Low, Close). Asset nodes serve as the primary data source for all downstream components.

\textbf{Indicators.}
Indicator nodes compute statistical or technical indicators over the values provided by upstream asset or selector nodes. The framework includes common indicators such as SMA, EMA, RSI, Bollinger Bands, and MACD, each producing one or more time-aligned output series. These outputs may then be used directly or passed through selectors for offsetting or field extraction.

\textbf{Selectors.}
Selector nodes extract specific values from asset or indicator outputs, optionally applying a time offset (e.g., previous bar). They provide a unified mechanism for selecting fields such as \textit{Close}, \textit{upper} (Bollinger upper band), or any indicator output. Selectors prepare data for condition nodes by ensuring that each operand refers to the correct value and temporal index.

\textbf{Conditions.}
Condition nodes evaluate boolean expressions over one or more selector outputs. Supported expressions include standard comparison operators ($>$, $<$, $\geq$, $\leq$, ==, !=) and logical operators ($\land$, $\lor$). The result is a boolean time series indicating when the specified condition holds, enabling constructs such as moving-average crossovers, breakout rules, or volatility filters.

\todo{Er ikke med i backtesteren - det hele er i condition noden}\textbf{Logic.}
Logical composition is achieved by chaining or nesting condition nodes. This allows the construction of higher-order logic such as multi-factor confirmations (e.g., RSI oversold \textit{and} price above SMA) or alternative-path triggers (e.g., condition A \textit{or} condition B). Logical nodes thus enable complex decision pipelines while maintaining clear graph structure.

\textbf{Signals.}
Signal nodes generate trading actions when their triggering condition is satisfied. Basic signal nodes produce directional entry instructions (long or short), while extended signal nodes additionally compute take-profit and stop-loss levels derived from percentage offsets relative to the entry price. Each signal is tied to a target asset node to ensure correct execution context.


\textbf{AI Prediction Nodes (AI-Nodes).}
AI-Nodes generate rolling machine-learning forecasts that update at every historical timestep. 
Each node receives a univariate price series from a preceding selector, which extracts a specific field (e.g., close price) from an asset's candlestick data. Using this input, the AINode applies a pre-trained LSTM time-series model configured through parameters such as the trading pair, timeframe, model name, and prediction horizon.

The node operates in a walk-forward manner. A fixed start date defines the beginning of the training window, while the end of the window advances with each bar in the dataset. At every bar $t$, the model loads its windowed training data and produces a vector of forecasts for the next $N$ periods (e.g., $\hat{p}_{t+1}, \hat{p}_{t+2}, \ldots, \hat{p}_{t+N}$). These predictions are stored as a nested structure, one forecast vector per historical bar, and can be accessed using indexed notation such as \todo{Det her er ikke rigtigt. Vi bruger SelectorNodes :)
}\texttt{now(ai).0} or \texttt{now(ai).1} for the first and second forward steps.

AI-Nodes enable strategies to incorporate ML-based expectations of short-or medium-term price movements, which can be combined with conventional condition nodes, logic nodes, or threshold rules to construct hybrid rule-based and AI-driven trading strategies.

A full overview and breakdown in UML-form of the different components can be seen in appendix \ref{} \todo{add to appendix}

%API Design
\subsection{API Design.}
\todo{Burde sættes i forlængelse af introduktionen og tilpasses}
We propose a modular and extensible API that provides a well-defined interface for the LSTM model, backtesting module and for strategy-creation. The API abstracts away low-level behaviour while exposing only essential operations required by higher-end components, following the OpenAPI specification. This design reduces integration complexity, enables consistent access across clients, and supports extensions without requiring architectural changes.

\subsection{Client (Front-End) Design}

We designed a web-based client front-end to provide an interactive environment for users to construct, configure, and back-test trading strategies. 
The platform was implemented in React and follows a strategy-builder paradigm, where users can place, connect, and parameterize computational nodes within a graphical interface. 
Each node represents a functional component of the strategy, such as assets, indicator, conditions, or machine-learning predictors. The directed connections between nodes specify the data-flow and execution order.

The client supports real-time validation of node graphs, such as checking for circular dependencies, contextual parameter editing, and visual feedback for errors or incompatible connections, ensuring that users can construct valid strategies without requiring direct knowledge of the underlying execution engine. 

A dedicated back-testing panel allows users to execute the constructed node graph against historical market data and analyze performance metrics. 

The interface therefore functions as both a modeling tool (similar in concept to node-based UML-style editors) and an experimentation environment, enabling users to iteratively design, test, and refine quantitative strategies through a highly visual and intuitive workflow.

%Communication Strategy
\subsection{Communication Strategy}.
\todo{Burde sættes i forlængelse af introduktionen og tilpasses}
We design a structured communication model based on a request/response pattern. This strategy enables efficient coordination between system modules, minimizing latency and ensures reliable message delivery under varying load conditions. By formalizing the communication, the system gains improved robustness and supports independent development and evaluation of interacting components.

%LSTM Implementation
\subsection{LSTM Implementation.}
\todo{Burde sættes i forlængelse af introduktionen og tilpasses}
A machine learning service was developed encapsulating a Long Short-Term Memory (LSTM)\todo{abbreviation consistency} network using TensorFlow. To address the non-stationary nature of financial time series, the implementation incorporates an automated preprocessing pipeline that transforms raw asset prices into logarithmic returns ($r_t = \ln(P_t / P_{t-1})$) prior to normalization via Min-Max scaling. The architecture utilizes a configurable sliding window approach for sequence generation, where a lookback parameter defines the number of historical observations used to predict the next value. The training pipeline supports configurable hyperparameters including the number of LSTM layers, hidden units, dropout rate, and batch size.

\subsection{Implemented Strategy Archetypes}
To validate the modular framework and investigate whether statistical indicators can function as "regime filters" for machine-learning predictions, we constructed three distinct classes of trading strategies using the node-based architecture. These archetypes represent fundamentally different approaches to algorithmic trading and enable controlled comparison between traditional, AI-driven, and hybrid methodologies.

\textbf{Statistical Strategies (Control).}
These strategies rely exclusively on \textit{Asset}, \textit{Indicator}, \textit{Selector}, and \textit{Condition} nodes, representing traditional rule-based algorithmic trading. Condition nodes evaluate relationships between technical indicators to generate trading signals without any machine learning component. Examples include Moving Average crossovers (e.g., SMA 20 crosses above SMA 50), Mean Reversion strategies based on Bollinger Bands, and momentum filters using the Relative Strength Index (RSI). These strategies establish a baseline for what can be achieved with purely statistical logic.

\textbf{AI-Only Strategies (Baseline).}
This class isolates the predictive capability of the \textit{AI-Nodes} by creating a direct pipeline from prediction to execution. The strategy graph consists of an Asset node feeding a Selector (to extract close price), connected to an AI-Node (producing LSTM forecasts), which then connects to a Condition node that evaluates whether the predicted price $\hat{p}_{t+n}$ exceeds the current price $p_t$ by a configurable threshold percentage. When this condition is satisfied, a Signal node generates a directional trade. This archetype measures the "raw" performance of the deep learning model without any statistical constraints, representing an aggressive, prediction-driven approach.

\textbf{Hybrid Strategies (Experimental).}
The primary experimental contribution involves Hybrid strategies that combine AI-Node predictions with statistical constraints within compound Condition nodes. Rather than treating statistical indicators as independent signal generators, these strategies use them as "regime filters" or "confirmation layers" for AI predictions. The Condition node evaluates a boolean expression that requires both the AI prediction criterion \textit{and} a statistical criterion to be satisfied simultaneously (e.g., \texttt{(predicted > current * 1.02) AND (price > SMA\_200)}). This topology tests the hypothesis that statistical context—such as trend direction, momentum state, or volatility regime—can reduce false positives in volatility-sensitive machine learning models while preserving high-confidence signals.

\subsection{Experimental Design and Asset Selection}
To rigorously test whether hybrid filtering provides consistent value across different market regimes, we implemented approximately 340 unique strategy configurations spanning all three archetypes. Each configuration varies parameters such as indicator periods, AI prediction horizons, threshold percentages, and filter combinations.

The experimental design employs a two-asset comparative approach to isolate the effects of market volatility on strategy performance:

\textbf{Bitcoin (BTC/USD, 2020--2025).}
Bitcoin represents a high-volatility, sentiment-driven asset class characterized by rapid price swings, asymmetric risk/reward profiles, and frequent regime changes between trending and mean-reverting behavior. The crypto market's 24/7 operation and susceptibility to external news shocks create a challenging environment where noise and signal are difficult to distinguish. This dataset enables evaluation of whether statistical filters can stabilize AI predictions during periods of extreme volatility and drawdown.

\textbf{Lockheed Martin (LMT, 2024--2025).}
Lockheed Martin, a large-cap defense contractor, represents a fundamentally-driven, low-volatility equity. Daily price movements are typically constrained, and the asset exhibits lower beta relative to broad market indices. This stability introduces a different challenge: in low-noise environments, overly sensitive AI models may generate excessive false signals from minor fluctuations, while statistical filters risk over-constraining valid predictions. The LMT dataset serves as a validation case to determine whether the hybrid approach generalizes beyond crypto-specific dynamics to traditional equity markets.

By comparing results across these two different asset classes, the study aims to identify whether the value of statistical filtering is universal or regime-dependent, and whether the optimal filter type (trend, momentum, volatility) varies with the underlying market structure.
