\section{Preliminary Work}
For the purposes of this project, the focus was primarily aimed at analysis of financial market data. While multiple domains were considered for evaluating hybrid time series prediction strategies, financial market data was ultimately selected due to practical reasons. A large amount of high-quality historical price data is mostly freely available from various sources, and this accessibility and reduced data acquisition challenges made it a primary choice.

The aim of the project, however, is not necessarily limited to financial analysis. Various types of time series can be passed to constructed hybrid models, regardless of their domain of origin. While some models may specialize in certain domains, or be trained to predict more accurately on certain markets, the fundamental principle of hybrid strategies will likely carry over to other domains.

The decision to utilize LSTM networks over more contemporary architectures, such as Transformer-based models, was primarily driven by the balance between predictive performance and implementation complexity. Although newer models may have offered improvements in accuracy or more interesting results, they would probably have required significantly larger datasets, computational resources, and more specialized knowledge to implement and train properly. \todo{citation needed?} For the scope of this project, the primary research objective is the evaluation of the hybrid strategy framework itself, rather than the development of novel deep learning architectures. LSTMs showcase a well-established standard in time series forecasting with extensive documentation and library support, which would allow efficient integration into the platform and ensure that development efforts remain focused on the system's modularity and the interaction between the machine learning and quantitative components. Furthermore, LSTMs are chosen specifically for their ability to retain information over long sequences, both enabling improved temporal feature capturing, as wekk as mitigating the "vanishing gradient" problem inherent in standard RNNs \cite{Hochreiter1997}. 

The training process is structured as a supervised learning task. Granted the utilization of financial data, the Open-High-Low-Close-Volume (OHLCV / OHLC) format will be used. At a given timestamp, five values are present. The starting and ending prices within the period, the highest and lowest recorded price, along with the volume of the period. This format and the handling of it is expounded upon in section \ref{dataaquisition}. The raw OHLCV data, specifically the closing price\todo{why specifically}, which is converted to a logarithmic return\todo{what is a logarithmic return, and why is it used} and is restructured using a sliding window technique, for a chosen lookback period $k$, the model learns to map a sequence of historical prices $X_t = \{x_{t-k}, \dots, x_{t-1}\}$ to the next target value $x_t$. To ensure that the model converges properly during training, the input data is normalized to the range $[0, 1]$ using Min-Max scaling, preventing large price values from destabilizing the weights of the neural network. \todo{kilde indsætter jeg snart}

The network architecture is constructed using the Keras functional API with TensorFlow as the backend. It consists of LSTM layers designed to extract temporal features, followed by fully connected Dense layers that map these features to a scalar output. The model is optimized using the Adam algorithm\todo{what is this, is it important to mention?}, minimizing the Mean\todo{uppercase m?}. \todo{kilde indsætter jeg snart}

\todo{Sektion om finansielle termer relevant for forståelse af resultatforklaring}
% forklaring af MA, SMA, EMA, RSI, momentum, beta, drawdown, candlestick / bar, pnl / running balance, bollinger bands, crossovers, breakout rules, volatility filters